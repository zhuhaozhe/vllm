# This vLLM Dockerfile is used to construct image that can build and run vLLM on x86 CPU platform.

FROM ubuntu:22.04

RUN apt-get update  -y \
    && apt-get install -y git wget vim numactl gcc-12 g++-12 python3 python3-pip libtcmalloc-minimal4 \
    && update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-12 10 --slave /usr/bin/g++ g++ /usr/bin/g++-12

RUN echo 'export LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libtcmalloc_minimal.so.4:$LD_PRELOAD' >> ~/.bashrc


RUN pip install --upgrade pip \
    && pip install wheel packaging ninja setuptools>=49.4.0 numpy==1.26.4

COPY ./ /workspace/vllm

WORKDIR /workspace/vllm

RUN pip install -v -r requirements-cpu.txt --extra-index-url https://download.pytorch.org/whl/cpu
# TODO: Remove it after the 2.3.1 official release
RUN unset http_proxy && pip install http://mlpc.intel.com/downloads/cpu/ipex-2.3.100/rc0_vllm_0528/intel_extension_for_pytorch-2.3.0+gitac44227-cp310-cp310-linux_x86_64.whl
RUN VLLM_TARGET_DEVICE=cpu python3 setup.py install

WORKDIR /workspace/

CMD ["/bin/bash"]
